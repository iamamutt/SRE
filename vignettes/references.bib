@article{NUTS,
 author = {Homan, Matthew D. and Gelman, Andrew},
 title = {The No-U-turn Sampler: Adaptively Setting Path Lengths in Hamiltonian Monte Carlo},
 journal = {Journal of Machine Learning Research},
 issue_date = {January 2014},
 volume = {15},
 number = {1},
 month = jan,
 year = {2014},
 issn = {1532-4435},
 pages = {1593--1623},
 numpages = {31},
 url = {http://dl.acm.org/citation.cfm?id=2627435.2638586},
 acmid = {2638586},
 publisher = {JMLR.org},
 keywords = {Bayesian inference, Hamiltonian Monte Carlo, Markov chain Monte Carlo, adaptive Monte Carlo, dual averaging},
}

@article{STAN,
   author = {Bob Carpenter and Andrew Gelman and Matthew Hoffman and Daniel Lee and Ben Goodrich and Michael Betancourt and Marcus Brubaker and Jiqiang Guo and Peter Li and Allen Riddell},
   title = {Stan: A Probabilistic Programming Language},
   journal = {Journal of Statistical Software, Articles},
   volume = {76},
   number = {1},
   year = {2017},
   keywords = {probabilistic programming; Bayesian inference; algorithmic differentiation; Stan},
   abstract = {Stan is a probabilistic programming language for specifying statistical models. A Stan program imperatively defines a log probability function over parameters conditioned on specified data and constants. As of version 2.14.0, Stan provides full Bayesian inference for continuous-variable models through Markov chain Monte Carlo methods such as the No-U-Turn sampler, an adaptive form of Hamiltonian Monte Carlo sampling. Penalized maximum likelihood estimates are calculated using optimization methods such as the limited memory Broyden-Fletcher-Goldfarb-Shanno algorithm. Stan is also a platform for computing log densities and their gradients and Hessians, which can be used in alternative algorithms such as variational Bayes, expectation propagation, and marginal inference using approximate integration. To this end, Stan is set up so that the densities, gradients, and Hessians, along with intermediate quantities of the algorithm such as acceptance probabilities, are easily accessible. Stan can be called from the command line using the cmdstan package, through R using the rstan package, and through Python using the pystan package. All three interfaces support sampling and optimization-based inference with diagnostics and posterior analysis. rstan and pystan also provide access to log probabilities, gradients, Hessians, parameter transforms, and specialized plotting.},
   issn = {1548-7660},
   pages = {1--32},
   doi = {10.18637/jss.v076.i01},
   url = {https://www.jstatsoft.org/v076/i01}
}

@article{Lewandowski2009,
title = "Generating random correlation matrices based on vines and extended onion method",
journal = "Journal of Multivariate Analysis",
volume = "100",
number = "9",
pages = "1989 - 2001",
year = "2009",
issn = "0047-259X",
doi = "doi.org/10.1016/j.jmva.2009.04.008",
url = "http://www.sciencedirect.com/science/article/pii/S0047259X09000876",
author = "Daniel Lewandowski and Dorota Kurowicka and Harry Joe",
keywords = "Dependence vines, Correlation matrix, Partial correlation, Onion method"
}

@article{Ghosh2015,
   author = {{Ghosh}, J. and {Li}, Y. and {Mitra}, R.},
    title = "{On the Use of Cauchy Prior Distributions for Bayesian Logistic Regression}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1507.07170},
 primaryClass = "stat.ME",
 keywords = {Statistics - Methodology},
     year = 2015,
    month = jul,
   adsurl = {http://adsabs.harvard.edu/abs/2015arXiv150707170G},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}
